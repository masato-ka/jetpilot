{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jetpilot - Training autopilot\n",
    "\n",
    "Now, we collected training data. dataset directory contain enough image as training data. Let's train own AI pilot. \n",
    "In this notebook, We do learning ResNet18 with own data and transfer lerning. Furthermore, We checking own AI pilot performance using Grad-CAM.\n",
    "\n",
    "Run below cell adn importing needs modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cae7bryMTfGv"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import glob\n",
    "import PIL.Image\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KK5zlxRxC9EY"
   },
   "source": [
    "## Data cleansing\n",
    "\n",
    "For good AI pilot , We must be remove bad training data. Bad training data are zero or little value slottle, image with large blurring. However dataset directory contain many hundred image. It is very hard work. I suggest to only clear zero value slottle data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf dataset/0.00_*.jpg\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "files = os.listdir('dataset')\n",
    "for target in files:\n",
    "    if target.split('.')[-1] != 'jpg':\n",
    "      continue\n",
    "    org = os.path.join('dataset', target)\n",
    "    image = PIL.Image.open(org)\n",
    "    image_resize = image.resize((224,224))\n",
    "    image_resize.save(org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VNwXOp65rn7B"
   },
   "source": [
    "## Create Dataset instance\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hrA9qF3XTr1k"
   },
   "outputs": [],
   "source": [
    "def get_speed(path):\n",
    "    \"\"\"Gets the speed value from the image filename\"\"\"\n",
    "    gets = path.split('_')\n",
    "    return float(gets[0])\n",
    "\n",
    "def get_steering(path):\n",
    "    \"\"\"Gets the steering value from the image filename\"\"\"\n",
    "    gets = path.split('_')\n",
    "    return float(gets[1])\n",
    "    \n",
    "class SSDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, directory, random_hflips=False):\n",
    "        self.directory = directory\n",
    "        self.random_hflips = random_hflips\n",
    "        self.image_paths = glob.glob(os.path.join(self.directory, '*.jpg'))\n",
    "        self.color_jitter = transforms.ColorJitter(0.3, 0.3, 0.3, 0.3)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        \n",
    "        image = PIL.Image.open(image_path)\n",
    "        x = float(get_speed(os.path.basename(image_path)))\n",
    "        y = float(get_steering(os.path.basename(image_path)))\n",
    "       \n",
    "        image = self.color_jitter(image)\n",
    "        image = transforms.functional.resize(image, (224, 224))\n",
    "        image = transforms.functional.to_tensor(image)\n",
    "        image = image.numpy()[::-1].copy()\n",
    "        image = torch.from_numpy(image)\n",
    "        image = transforms.functional.normalize(image, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        \n",
    "        return image, torch.tensor([x, y]).float()\n",
    "    \n",
    "dataset = SSDataset('./dataset', random_hflips=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset into train and test sets\n",
    "Once we read dataset, we will split data set in train and test sets. In this example we split train and test a 90%-10%. The test set will be used to verify the accuracy of the model we train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jKdw5jyuXEOt"
   },
   "outputs": [],
   "source": [
    "test_percent = 0.1\n",
    "num_test = int(test_percent * len(dataset))\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - num_test, num_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data loaders to load data in batches\n",
    "We use DataLoader class to load data in batches, shuffle data and allow using multi-subprocesses. In this example we use batch size of 64. Batch size will be based on memory available with your GPU and it can impact accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YsGM3WluTsrl"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define neural network model\n",
    "\n",
    "Now, We have small dataset for Deep learning. That is not enough dataset for Learning. So we using transfer learning technic with ResNet. We can load pretrained model of ResNet18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PQPE4TAtTvQI"
   },
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet 18 trained for classification task. We want to two values of regression as speed and steering. Replacing final layer of ResNet 18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z5NDFyf1TxI9"
   },
   "outputs": [],
   "source": [
    "model.fc = torch.nn.Linear(512, 2)\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "\n",
    "# Frozen for modle layer1 to layer3\n",
    "for l in model.layer1.parameters():\n",
    "    l.requires_grad=False\n",
    "for l in model.layer2.parameters():\n",
    "    l.requires_grad=False\n",
    "for l in model.layer3.parameters():\n",
    "    l.requires_grad=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Regression:\n",
    "    \n",
    "We train for 70 epochs and save best model if the loss is reduced. Takes about a hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "w5BiRl1CTzJo",
    "outputId": "ac44d733-d745-4068-ed82-60183406b933"
   },
   "outputs": [],
   "source": [
    "\n",
    "EARLY_STOP = True\n",
    "\n",
    "\n",
    "NUM_EPOCHS = 70\n",
    "BEST_MODEL_PATH = 'best_steering_model_ResNet.pth'\n",
    "best_loss = 1e9\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "es_counter = 0 \n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, labels in iter(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = F.mse_loss(outputs, labels)\n",
    "        loss.backward()\n",
    "        train_loss += float(loss)\n",
    "        optimizer.step()\n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    for images, labels in iter(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = F.mse_loss(outputs, labels)\n",
    "        test_loss += float(loss)\n",
    "    test_loss /= len(test_loader)\n",
    "    print('%d, %f, %f' % (epoch, train_loss, test_loss))\n",
    "    if test_loss < best_loss:\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        best_loss = test_loss\n",
    "        es_counter=0\n",
    "    else:\n",
    "        if es_counter == 7 and EARLY_STOP:\n",
    "            print(\"Early Stopping EPOCH[{}], val_loss {:4f}\".format(epoch, best_loss))\n",
    "            break\n",
    "        else:\n",
    "            es_counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check your model result.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "5W885QJDiRoU",
    "outputId": "d0bf60f9-45d5-4546-a43c-7119e781cd96"
   },
   "outputs": [],
   "source": [
    "TEST_DATA_IMAGE = './dataset/0.70_-0.66_ab62b41c-d6fa-11e9-b126-72b5f773b75d.jpg'\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(512, 2)\n",
    "model.load_state_dict(torch.load('best_steering_model_ResNet.pth'))\n",
    "model = model.to(device)\n",
    "model = model.eval()\n",
    "image_path = TEST_DATA_IMAGE\n",
    "image = PIL.Image.open(image_path)\n",
    "image = transforms.functional.resize(image, (224, 224))\n",
    "image = transforms.functional.to_tensor(image)\n",
    "image = image.numpy()[::-1].copy()\n",
    "image = torch.from_numpy(image)\n",
    "image = transforms.functional.normalize(image, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]).to(device)\n",
    "outputs = model(image[None, ...])\n",
    "print(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = PIL.Image.open(image_path)\n",
    "image_orig_size = image.size\n",
    "\n",
    "sample_image = transforms.functional.resize(image, (224, 224))\n",
    "\n",
    "\n",
    "sample_image = transforms.functional.to_tensor(sample_image)\n",
    "sample_image = sample_image.numpy()[::-1].copy()\n",
    "sample_image = torch.from_numpy(sample_image)\n",
    "sample_image = transforms.functional.normalize(sample_image, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZLP4ggUj7PSV"
   },
   "outputs": [],
   "source": [
    "# https://tech.jxpress.net/entry/2018/12/12/130057\n",
    "# https://jacobgil.github.io/deeplearning/vehicle-steering-angle-visualizations\n",
    "class GradCAM:\n",
    "    def __init__(self, model, feature_layer):\n",
    "        self.model = model\n",
    "        self.feature_layer = feature_layer\n",
    "        self.model.eval()\n",
    "        self.feature_grad = None\n",
    "        self.feature_map = None\n",
    "        self.hooks = []\n",
    "\n",
    "        # 最終層逆伝播時の勾配を記録する\n",
    "        def save_feature_grad(module, in_grad, out_grad):\n",
    "            self.feature_grad = out_grad[0]\n",
    "        self.hooks.append(self.feature_layer.register_backward_hook(save_feature_grad))\n",
    "\n",
    "        # 最終層の出力 Feature Map を記録する\n",
    "        def save_feature_map(module, inp, outp):\n",
    "            self.feature_map = outp[0]\n",
    "        self.hooks.append(self.feature_layer.register_forward_hook(save_feature_map))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def backward_on_target(self,output):\n",
    "        self.model.zero_grad()\n",
    "        output.backward()\n",
    "\n",
    "    def clear_hook(self):\n",
    "        for hook in self.hooks:\n",
    "            hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "grad_cam = GradCAM(model=model, feature_layer=list(model.layer4.modules())[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = grad_cam.forward(sample_image[None, ...])\n",
    "print(model_output)\n",
    "#model_output.backward()\n",
    "grad_cam.backward_on_target(model_output[0][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Get feature gradient\n",
    "feature_grad = grad_cam.feature_grad.data.cpu().numpy()[0]\n",
    "# Get weights from gradient\n",
    "weights = np.mean(feature_grad, axis=(1, 2))  # Take averages for each gradient\n",
    "# Get features outputs\n",
    "feature_map = grad_cam.feature_map.data.cpu().numpy()\n",
    "grad_cam.clear_hook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cam\n",
    "cam = np.sum((weights * feature_map.T), axis=2).T\n",
    "cam = np.maximum(cam, 0)  # apply ReLU to cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(cam*10000).astype(np.uint8)\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "cam = cv2.resize(cam, (224,224))\n",
    "cam = (cam - np.min(cam)) / (np.max(cam) - np.min(cam))  # Normalize between 0-1\n",
    "cam = np.uint8(cam * 255)  # Scale between 0-255 to visualize\n",
    "plt.imshow(cam)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_heatmap = np.expand_dims(cam, axis=0).transpose(1,2,0)\n",
    "org_img = np.asarray(image.resize((224,224)))\n",
    "img_with_heatmap = np.multiply(np.float32(activation_heatmap), np.float32(org_img))\n",
    "img_with_heatmap = img_with_heatmap / np.max(img_with_heatmap)\n",
    "org_img = cv2.resize(org_img, image_orig_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(org_img)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(cv2.resize(np.uint8(255 * img_with_heatmap), image_orig_size))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ResNet-Jetbot",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
